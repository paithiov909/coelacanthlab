---
title: 分析プロセスの設計
author: paithiov909
date: '2020-04-21'
categories:
  - Concepts
slug: design
---

## テキストを分析して何がしたいのか

入門的な本だと「テキストマイニングとは何か」みたいな話から入るような気がします。ここではとくに入門的なあれをめざしてはいませんが、しかし、すこし考えてみましょう。テキストマイニングとはなんでしょうか。

自然言語処理というのは、まあいろいろと思想はあるでしょうが、総じて「テキストを機械的に処理してごにょごにょする」技術のことだと思います。自然言語処理界隈の論文などを眺めていると、その範囲はわりと広くて、音声処理だったり対話文生成だったりも含まれる印象です。そのなかでもテキストマイニングというと、「テキストから特徴量をつくって何かやる」みたいな部分にフォーカスしてくるのではないでしょうか。

素人考えですが、テキストマイニングとはしたがってデータ分析のことです。そのため、前提としてテキストを分析して何がしたいのか（＝何ができるのか）を見通しよくしておくと、嬉しいことが多い気がします。

## CRISP-DM

CRISP-DM ([Cross-Industry Standard Process for Data Mining](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)) は、IBMを中心としたコンソーシアムが提案したデータマイニングのための標準プロセスです。これはデータ分析をビジネスに活かすことを念頭においてつくられた「課題ドリブン」なプロセスであるため、場合によってはそのまま採用できないかもしれませんが、こうした標準プロセスを押さえておくことは分析プロセスを設計するうえで有用だと思います。

CRISP-DMは以下の6つの段階（phases）を行ったり来たりすることで進められていきます。

- Business Understanding
- Data Understanding
- Data Preparation
- Modeling
- Evaluation
- Deployment

それぞれの段階は次に挙げるようなタスクに分解されます ([*The CRISP-DM User Guide*](http://lyle.smu.edu/~mhd/8331f03/crisp.pdf) より抜粋)。

### Business Understanding

- Determine Business Objectives (ビジネスの課題を把握する)
- Situation Assessment (データ分析に利用できる資源を確認し、分析をおこなった場合に予想される効果を評価する)
- Determine Data Mining Goal (データマイニングによって達成したいことを決定する)
- Produce Project Plan (達成したいことをやるために採りうる手法を確認する)

### Data Understanding

- Collect Initial Data
- Describe Data
- Explore Data
- Verify Data Quality

### Data Preparation

- Select Data
- Clean Data
- Construct Data
- Integrate Data
- Format Data

### Modeling

- Select Modeling Technique
- Generate Test Design
- Build Model
- Assess Model

### Evaluation

- Evaluate Results
- Review Process
- Determine Next Steps

### Deployment

- Plan Deployment
- Plan Monitoring and Maintenance
- Produce Final Report
- Review Project

## テキストマイニングでできること

CRISP-DMはデータ分析を通じて達成したいことから分析をスタートしていく、ある意味でトップダウン的なプロセスですが、そうはいってもデータからの知見の発掘はそんなにトップダウン一直線にはうまくいかないものです。いわばボトムアップ的に、段階を「行ったり来たり」しながら分析を進めるためには、データ分析でとれるカードをなんとなく把握しておく必要があります。

これも素人考えですが、私たちがデータ分析でとれるカードってだいたい次の４つくらいのものです（文書集合が時系列としてもてるようなデータだと異常検知などの応用もありそうですが）。

- モデルをつくって何かの回帰をする
- モデルをつくって何かの分類をする
- グループに分けて違いを評価する（教師なしの分類、検定など）
- ルールマイニング

逆に、これらの落としどころに持ち込むための特徴量をどうにかして作るというのがテキストマイニングの大部分をしめるように思います。そして、それらの特徴量は基本的に何かを数えた**頻度**または**比率**とそれらを変換したものだと思っておくとすっきりします。数を数える「何か」というのは、たとえば**語**だったり**品詞**だったり、それらの**Ngram**だったり、その他のタグ付けされた情報だったりします。

## テキストマイニングの流れ

イメージ的にはこんな感じです。

1. 分析したいテキストをいっぱい集める
  - 分析して何がしたいか考える
  - そのためにつくるべき特徴量を考える
2. 特徴量をつくる
  - テキストの前処理
  - トークナイズ
  - 集計
  - 特徴量の変換や補完
3. 分析する
  - 特徴量をつかってごにょごにょする
  - 得られた結果を評価する
4. （必要に応じて）得られた知見を活かす




