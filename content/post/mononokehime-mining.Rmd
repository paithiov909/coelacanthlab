---
title: もののけ姫を題材にした格パターンマイニングのお試し
author: paithiov909
date: '2020-07-19'
lastmod: "`r Sys.Date()`"
slug: mononokehime-mining
categories: []
tags:
  - NLP
description: '「AをBにする」という構文を抽出してみてる'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  tidy = "styler",
  collapse = TRUE,
  comment = "#>"
)

stopifnot(require(tidyverse))

URL <- "https://lolipop-teru.ssl-lolipop.jp/ghibli/mononoke.html"
```

## 台詞の取得

もののけ姫の台詞を題材にしてみる。

有名どころのジブリ作品だとファンが台詞をすべて書き起こして公開していたりする。すべて読めてしまうのは権利的にどうなのかというのはあるが、ググると出てくるのであまり深く考えないことにした。

```{r}
## 'キャラ名「セリフ(ある場合、読みがな)」'という形式で書かれている
sentences <- URL %>%
  rvest::html_session() %>%
  rvest::html_nodes("p.serif") %>%
  rvest::html_text(trim = TRUE) %>%
  stringr::str_replace_all(enc2utf8("\u300d"), "") %>%
  stringr::str_replace_all("\\([ぁ-ん]+\\)", "") %>%
  stringr::str_split(fixed(enc2utf8("\u300c"))) %>%
  purrr::keep(. != "") %>%
  purrr::keep(~ length(.) == 2) %>%
  purrr::map_dfr(~ tibble::tibble(
    character = .[1],
    sentence = .[2]
  ))
```

## 前処理

いわゆる注ぎ足しのタレ。今回の題材についてはそんなに重要じゃない気もする。

```{r}
normalize <- function(str) {
  str %>%
    stringr::str_replace_all("\u2019", "\'") %>%
    stringr::str_replace_all("\u201d", "\"") %>%
    stringr::str_replace_all("[\u02d7\u058a\u2010\u2011\u2012\u2013\u2043\u207b\u208b\u2212]", "-") %>%
    stringr::str_replace_all("[\ufe63\uff0d\uff70\u2014\u2015\u2500\u2501\u30fc]", enc2utf8("\u30fc")) %>%
    stringr::str_replace_all("[~\u223c\u223e\u301c\u3030\uff5e]", "~") %>%
    stringr::str_replace_all("[\\.]+", enc2utf8("\u2026\u2026")) %>%
    stringr::str_remove_all("[:blank:]") %>%
    stringr::str_remove_all("[:cntrl:]") %>%
    return()
}

doc <- sentences %>%
  dplyr::mutate(sentence = zipangu::str_conv_normalize(sentence)) %>%
  dplyr::mutate(text = normalize(sentence)) %>%
  dplyr::mutate(character = as.factor(character)) %>%
  tibble::rowid_to_column("doc_id")
```

{udpipe}で解析する。

```{r}
annotation <- udpipe::udpipe(doc, object = "japanese")
annotation <- doc %>%
  dplyr::select(doc_id, character) %>%
  dplyr::mutate(doc_id = as.character(doc_id)) %>%
  dplyr::left_join(annotation, by = "doc_id")
```

プロットして解析結果を確認してみる。見た感じ、そこそこ正しそう。

```{r}
textplot::textplot_dependencyparser(
  dplyr::filter(annotation, doc_id == "48" & sentence_id == "7")
)
```

ただ、漢字がひらがなに開かれている箇所には弱そうかもしれない。

```{r}
textplot::textplot_dependencyparser(
  dplyr::filter(annotation, doc_id == "48" & sentence_id == "1")
)
```

## Keywords(collocation) extraction

こんな感じでコロケーションをキーワードとして抽出できる。

```{r}
udpipe::keywords_collocation(
  dplyr::filter(annotation, upos %in% c("PROPN", "NOUN")),
  term = "lemma",
  group = c("doc_id", "sentence_id"),
  ngram_max = 4L
) %>%
  dplyr::select(1:7) %>%
  dplyr::top_n(10, desc(freq)) %>%
  knitr::kable()
```

適当に助詞と動詞のコロケーションを抽出した。このなかから「を に する」という表現に注目してみることにする。

```{r}
words <- udpipe::keywords_collocation(
  dplyr::filter(annotation, upos %in% c("SCONJ", "ADP", "VERB")),
  term = "lemma",
  group = c("doc_id", "sentence_id"),
  ngram_max = 6L
)

words %>%
  dplyr::select(1:7) %>%
  dplyr::top_n(10, desc(freq)) %>%
  knitr::kable()
```

具体的にどのような表現として出現しているのか確認するために、「を に する」という表現を力技で抽出する（それぞれの文をパースしているわけではないので、そうは言っていない表現も拾ってしまうので注意）。

```{r}
d <- udpipe::udpipe(
  iconv("折り紙を折って紙飛行機にする", to = "UTF-8"),
  object = "japanese"
)

extract_collocation <- function(d) {
  res <- d %>%
    dplyr::rowwise() %>%
    dplyr::mutate(head_token = ifelse(
      .data[["head_token_id"]] == "0",
      "EOS",
      subset(d, token_id == .data[["head_token_id"]])$token
    )) %>%
    dplyr::group_by(doc_id, sentence_id) %>%
    dplyr::group_map(function(sentence, keys){
      cond <- sentence %>%
        dplyr::pull(lemma) %>%
        stringr::str_c(collapse = "\t") %>%
        purrr::map(~ ifelse(all(c(
            stringr::str_detect(., "\tを"),
            stringr::str_detect(., "\tに"),
            stringr::str_detect(., "\tする")
          )),
          TRUE,
          FALSE
        )) %>%
        purrr::flatten_lgl()

      return(
        ifelse(
          cond,
          stringr::str_c(
            keys,
            ":",
            sentence %>%
              dplyr::mutate(heading = lag(token, 1)) %>%
              dplyr::filter(token == "を") %>%
              dplyr::pull(heading),
            "を",
            sentence %>%
              dplyr::mutate(heading = lag(token, 1)) %>%
              dplyr::filter(token == "に") %>%
              dplyr::pull(heading),
            "に",
            sentence %>%
              dplyr::filter(lemma == "する") %>%
              dplyr::pull(lemma),
            sep = " ",
            collapse = ";"
          ),
          character(0)
      ))
    }) %>%
    purrr::map_dfr(~ tibble::tibble(collocation = .))
  return(res)
}

extract_collocation(d)
```

こうなる。

```{r}
annotation %>%
  extract_collocation() %>%
  tidyr::drop_na() %>%
  knitr::kable()
```

## セッション情報

```{r}
sessioninfo::session_info()
```
